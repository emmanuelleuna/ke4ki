# Paper2Contribution â€“ KE4KI Pipeline  

This repository contains the code and experiments developed for my Master's Thesis:  
**"Paper2Contribution â€“ KE4KI: Knowledge Extraction for Knowledge Indexing in Digital Libraries"**.  
The goal of this work is to transform unstructured PDF documents (e.g., food composition tables) into structured, semantically rich contributions for integration into the **Open Research Knowledge Graph (ORKG)**.  

---

## ğŸš€ Overview  

The pipeline combines **instruction-tuned Large Language Models (LLMs)** with **template-guided prompting** and **schema validation** to extract domain-specific knowledge.  
It automatically maps extracted entities and relations to an ORKG template and indexes them into the knowledge graph.  

### Key Features  
- **PDF â†’ JSON conversion** with text segmentation.  
- **Knowledge extraction** using Flan-T5 with zero-shot, few-shot, and role-based prompting strategies.  
- **Schema validation** using Pydantic to ensure structural correctness.  
- **Knowledge indexing** into ORKG via REST API.  
- Support for **benchmarking** with and without validation.  

---

## ğŸ“‚ Repository Structure  

ğŸ“ paper2contribution-ke4ki
â”‚
â”œâ”€â”€ data/ # Dataset used for training and evaluation (JSON/JSONL)
â”œâ”€â”€ notebooks/ # Jupyter notebooks for data exploration & experiments
â”œâ”€â”€ src/ # Main pipeline source code
â”‚ â”œâ”€â”€ extraction/ # LLM-based knowledge extraction
â”‚ â”œâ”€â”€ validation/ # Schema validation logic (Pydantic)
â”‚ â”œâ”€â”€ indexing/ # ORKG API integration for indexing
â”‚ â””â”€â”€ utils/ # Helper functions and utilities
â”œâ”€â”€ results/ # Evaluation results (ROUGE, BLEU, Precision/Recall)
â”œâ”€â”€ requirements.txt # Python dependencies
â””â”€â”€ README.md # This file

